{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create reusable loading animation class\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class LoadingAnimation:\n",
    "    def __init__(self):\n",
    "        self.stop_event = threading.Event()\n",
    "        self.animation_thread = None\n",
    "\n",
    "    def _animate(self, message=\"Loading\"):\n",
    "        chars = \"/—\\\\|\"\n",
    "        while not self.stop_event.is_set():\n",
    "            for char in chars:\n",
    "                sys.stdout.write('\\r' + message + '... ' + char)\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(0.1)\n",
    "                if self.stop_event.is_set():\n",
    "                    sys.stdout.write(\"\\n\")\n",
    "                    break\n",
    "\n",
    "    def start(self, message=\"Loading\"):\n",
    "        self.stop_event.clear()\n",
    "        self.animation_thread = threading.Thread(target=self._animate, args=(message,))\n",
    "        self.animation_thread.daemon = True\n",
    "        self.animation_thread.start()\n",
    "\n",
    "    def stop(self, completion_message=\"Complete\"):\n",
    "        self.stop_event.set()\n",
    "        if self.animation_thread:\n",
    "            self.animation_thread.join()\n",
    "        print(f\"\\r{completion_message} ✓\")\n",
    "\n",
    "# Use the animation for pip install\n",
    "loader = LoadingAnimation()\n",
    "loader.start(\"Installing\")\n",
    "%pip install -r requirements.txt -q\n",
    "loader.stop(\"Installation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Define a fake `load_dotenv` function\n",
    "def _load_dotenv(*args, **kwargs):\n",
    "    env_path = kwargs.get('dotenv_path', '.env')  # Default to '.env'\n",
    "    parsed_env = dotenv_values(env_path)\n",
    "\n",
    "    # Manually set valid key-value pairs\n",
    "    for key, value in parsed_env.items():\n",
    "        if key and value:  # Check for valid key-value pairs\n",
    "            os.environ[key] = value\n",
    "\n",
    "dotenv.load_dotenv = _load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and Setup\n",
    "Initial imports for the CrewAI Flow and Crew and setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from typing import Any, List\n",
    "\n",
    "# Importing Crew related components\n",
    "from crewai import LLM\n",
    "\n",
    "# Importing CrewAI Flow related components\n",
    "from crewai.flow import Flow, listen, start, persist, or_, router\n",
    "from crewai.flow.flow import FlowState\n",
    "\n",
    "# Apply a patch to allow nested asyncio loops in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing for Llama 3.3 Prompting Template\n",
    "\n",
    "When using different models the ability to go a lower level and change the prompting template can drastically improve the performance of the model, you want to make sure to watch for the model's training prompt patterns and adjust accordingly.\n",
    "\n",
    "For Meta's Llama you can find it [in here](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#prompt-template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents Prompting Template for Llama 3.3\n",
    "system_template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{{ .System }}<|eot_id|>\"\"\"\n",
    "prompt_template=\"\"\"<|start_header_id|>user<|end_header_id|>{{ .Prompt }}<|eot_id|>\"\"\"\n",
    "response_template=\"\"\"<|start_header_id|>assistant<|end_header_id|>{{ .Response }}<|eot_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import yaml\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import DatabricksQueryTool\n",
    "\n",
    "# Load agent and task configurations from YAML files\n",
    "with open('config/data_analysis_agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('config/data_analysis_tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)\n",
    "\n",
    "db_tool = DatabricksQueryTool(\n",
    "  default_catalog='workspace',\n",
    "  default_schema='default',\n",
    "  default_warehouse_id='8ae5109e27f6a957'\n",
    ")\n",
    "\n",
    "# Define the agents for our movie analysis crew\n",
    "movie_information_agent = Agent(\n",
    "    config=agents_config['movie_information_agent'],\n",
    "    system_template=system_template,\n",
    "    prompt_template=prompt_template,\n",
    "    response_template=response_template,\n",
    "    tools=[db_tool]\n",
    ")\n",
    "\n",
    "movie_recommendation_agent = Agent(\n",
    "    config=agents_config['movie_recommendation_agent'],\n",
    "    system_template=system_template,\n",
    "    prompt_template=prompt_template,\n",
    "    response_template=response_template\n",
    ")\n",
    "\n",
    "# Define the tasks for our crew\n",
    "movie_information_task = Task(\n",
    "    description=tasks_config['movie_information_task']['description'],\n",
    "    expected_output=tasks_config['movie_information_task']['expected_output'],\n",
    "    agent=movie_information_agent\n",
    ")\n",
    "\n",
    "movie_recommendation_task = Task(\n",
    "    description=tasks_config['movie_recommendation_task']['description'],\n",
    "    expected_output=tasks_config['movie_recommendation_task']['expected_output'],\n",
    "    agent=movie_recommendation_agent\n",
    ")\n",
    "\n",
    "# Create the crew\n",
    "movie_analysis_crew = Crew(\n",
    "    agents=[movie_information_agent, movie_recommendation_agent],\n",
    "    tasks=[movie_information_task, movie_recommendation_task],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationalFlowState(FlowState):\n",
    "  \"\"\"\n",
    "  State for the conversational flow\n",
    "  \"\"\"\n",
    "  message: str = \"\"\n",
    "  query_result: List[Any] = []\n",
    "  conversation_history: List[Any] = []\n",
    "  step_timings: dict = {}\n",
    "  llm_call_time: float = 0\n",
    "  search_time: float = 0\n",
    "\n",
    "@persist()\n",
    "class ConversationalFlow(Flow[ConversationalFlowState]):\n",
    "  @start()\n",
    "  def start_conversation(self):\n",
    "    print(f\"# Starting conversation\\n\")\n",
    "    self.llm = LLM(model=\"groq/llama-3.3-70b-versatile\")\n",
    "\n",
    "  @router(or_('start_conversation', 'answer_user_message', 'execute_movies_crew'))\n",
    "  def listen_for_user_input(self):\n",
    "    message = input(\"Enter your message: \")\n",
    "    if message.lower() == \"exit\":\n",
    "      pass\n",
    "    else:\n",
    "      self.state.message = message\n",
    "      self.state.conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "      return 'message_received'\n",
    "\n",
    "  @router('message_received')\n",
    "  def process_user_input(self):\n",
    "    messages = self.state.conversation_history.copy()\n",
    "    messages.append(\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\"Check if you need more details about movies to answer.\n",
    "                    Only ask for more info if the question requires specific movie facts.\n",
    "\n",
    "                    If you have enough info, just reply 'complete'.\n",
    "                    If you need more info, reply with one search sentence.\n",
    "\n",
    "                    Look at our chat history and my message.\n",
    "                    Decide if you can give a good answer with what you know.\"\"\"\n",
    "    })\n",
    "\n",
    "    response = self.llm.call(messages)\n",
    "\n",
    "    if response == 'complete':\n",
    "      return 'answer'\n",
    "    else:\n",
    "      return 'run_crew'\n",
    "\n",
    "  @listen('run_crew')\n",
    "  def execute_movies_crew(self):\n",
    "    # Kickoff the movie analysis crew with the user's message\n",
    "    crew_response = movie_analysis_crew.kickoff(\n",
    "        inputs={\n",
    "            \"user_history\": \"\\n\".join([msg[\"content\"] for msg in self.state.conversation_history])\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add the crew's response to the conversation history\n",
    "    self.state.conversation_history.append({\"role\": \"assistant\", \"content\": crew_response.raw})\n",
    "    print(f\"# Assistant response: {crew_response.raw}\\n\")\n",
    "\n",
    "  @listen('answer')\n",
    "  def answer_user_message(self):\n",
    "    response = self.llm.call(self.state.conversation_history)\n",
    "\n",
    "    self.state.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    print(f\"# Assistant response: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = ConversationalFlow()\n",
    "flow.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
